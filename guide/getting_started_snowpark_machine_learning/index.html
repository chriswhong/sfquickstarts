
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Machine Learning with Snowpark Python: - Credit Card Approval Prediction</title>

  
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5Q8R2G');</script>
  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-08H27EW14N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-08H27EW14N');
</script>

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://quickstarts.snowflake.com/elements/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5Q8R2G"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <google-codelab-analytics gaid="UA-41491190-9"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="getting_started_snowpark_machine_learning"
                  title="Machine Learning with Snowpark Python: - Credit Card Approval Prediction"
                  environment="web"
                  feedback-link="https://github.com/Snowflake-Labs/sfguides/issues">
    
      <google-codelab-step label="Overview" duration="5">
        <p>Python is the language of choice for Data Science and Machine Learning workloads. Snowflake has long supported Python via the Python Connector, allowing data scientists to interact with data stored in Snowflake from their preferred Python environment. This did, however, require data scientists to write verbose SQL queries. To provide a more friendly, expressive, and extensible interface to Snowflake, we built <strong>Snowpark Python</strong>, a native Python experience with a pandas and PySpark-like API for data manipulation. This includes a client-side API to allow users to write Python code in a Spark-like API without the need to write verbose SQL. Python UDF and Stored Procedure support also provides more general additional capabilities for compute pushdown.</p>
<p>Snowpark includes client-side APIs and server-side runtimes that extends Snowflake to popular programming languages including Scala, Java, and Python. Ultimately, this offering provides a richer set of tools for Snowflake users (e.g. Python&#39;s extensibility and expressiveness) while still leveraging all of Snowflake&#39;s core features, and the underlying power of SQL, and provides a clear path to production for machine learning products and workflows.</p>
<p>A key component of Snowpark for Python is that you can &#34;Bring Your Own IDE&#34;- anywhere that you can run a Python kernel, you can run client-side Snowpark Python. You can use it in your code development the exact same way as any other Python library or module. In this quickstart, we will be using Jupyter Notebooks, but you could easily replace Jupyter with any IDE of your choosing.</p>
<p>Throughout this quickstart, we will specifically explore the power of the Snowpark Python Dataframe API, as well as server-side Python runtime capabilities, and how Snowpark Python can enable and accelerate end-to-end Machine Learning workflows.</p>
<p>The source code for this quickstart is available on <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning" target="_blank">GitHub</a>.</p>
<h2 is-upgraded>Prerequisites</h2>
<ul>
<li>Working knowledge of <a href="https://www.udemy.com/course/data-analysis-with-python-and-pandas/" target="_blank">Python</a></li>
<li>Familiarity with <a href="https://quickstarts.snowflake.com/guide/getting_started_with_snowflake/index.html#0" target="_blank">Snowflake</a></li>
</ul>
<h2 class="checklist" is-upgraded>What You&#39;ll Learn</h2>
<ul class="checklist">
<li>Loading and transforming data via Snowpark</li>
<li>Defining Stored Procedures for non-SQL-based Data Transformations</li>
<li>Defining Stored Procedures for training different machine learning models</li>
<li>Defining User Defined Functions for distributed scoring of machine learning models</li>
<li>Using hyper paratemer tuning in Stored Procedures</li>
</ul>
<h2 is-upgraded>What You&#39;ll Need</h2>
<ul>
<li>A free <a href="https://signup.snowflake.com/" target="_blank">Snowflake Trial Account</a></li>
<li><a href="https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda" target="_blank">Anaconda Integration enabled by ORGADMIN</a></li>
<li>Python 3.8</li>
<li>Jupyter Notebook</li>
</ul>
<h2 is-upgraded>What You&#39;ll Build</h2>
<p>You will build an end-to-end data science workflow leveraging Snowpark for Python</p>
<ul>
<li>to load, clean and prepare data</li>
<li>to train different machine learning models using Python Stored Procedures</li>
<li>to deploy the trained models in Snowflake using Python User Defined Functions (UDFs)</li>
</ul>
<p>The end-to-end workflow will look like this:</p>
<p class="image-container"><img src="img/d035925842c3b5aa.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Use-Case: Credit Card Approval Prediction" duration="3">
        <p>You are part of a team of data engineers and data scientists at a banking company that has been tasked to identify high-risk customers using a machine learning based solution. The goal is to give a recommendation to either approve or reject the issueing of a credit card.</p>
<p>To build this, you have access to customer demographic and credit history data. Using Snowpark, we will ingest, analyze and transform this data to train a model that will then be deployed inside Snowflake to score new data.</p>
<p>The dataset you are using is part of a Kaggle competition that can be found here:<br><a href="https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction" target="_blank">Kaggle: Credit Card Approval Prediction</a></p>


      </google-codelab-step>
    
      <google-codelab-step label="Python Environment Setup" duration="5">
        <p>Let&#39;s set up the Python environment necessary to run this quickstart:</p>
<p>First, clone the source code for this repo to your local environment:</p>
<pre><code language="language-bash" class="language-bash">git clone https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning.git
cd sfguide-getting-started-machine-learning/
</code></pre>
<h2 is-upgraded>Snowpark Python via Anaconda</h2>
<p>If you are using <a href="https://www.anaconda.com/products/distribution" target="_blank">Anaconda</a> on your local machine, create a conda env for this quickstart:</p>
<pre><code language="language-bash" class="language-bash">conda env create -f conda_env.yml
conda activate pysnowpark
</code></pre>
<p>Conda will automatically install <code>snowflake-snowpark-python</code> and all other dependencies for you.</p>
<p>Now, launch Jupyter Notebook on your local machine:</p>
<pre><code language="language-bash" class="language-bash">jupyter notebook
</code></pre>
<h2 is-upgraded>Snowpark with your own Environment</h2>
<p>If you decide to bring your own Python environment, please make sure to have the following packages installed:</p>
<ul>
<li><a href="https://pypi.org/project/snowflake-snowpark-python/" target="_blank">Snowpark</a></li>
<li><a href="https://pypi.org/project/snowflake-snowpark-python/" target="_blank">Pandas</a></li>
<li><a href="https://pypi.org/project/numpy/" target="_blank">NumPy</a></li>
<li><a href="https://pypi.org/project/scikit-learn/" target="_blank">scikit-learn</a></li>
<li><a href="https://pypi.org/project/lightgbm/" target="_blank">LightGBM</a></li>
<li><a href="https://pypi.org/project/xgboost/" target="_blank">XGBoost</a></li>
<li><a href="https://pypi.org/project/scipy/" target="_blank">SciPy</a></li>
<li><a href="https://pypi.org/project/seaborn/" target="_blank">Seaborn</a></li>
<li><a href="https://pypi.org/project/cloudpickle/" target="_blank">cloudpickle</a></li>
<li><a href="https://pypi.org/project/cachetools/" target="_blank">cachetools</a></li>
<li><a href="https://pypi.org/project/imbalanced-learn/" target="_blank">imbalanced-learn</a></li>
<li><a href="https://pypi.org/project/optuna/" target="_blank">optuna</a></li>
</ul>
<aside class="special"><p> There is a known issue with running Snowpark Python on Apple M1 chips due to memory handling in pyOpenSSL. Please refer to the Snowpark documentation to solve this issue: <a href="https://docs.snowflake.com/en/developer-guide/snowpark/python/setup.html#prerequisites" target="_blank">Issue with running Snowpark Python on Apple M1 chips</a></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Snowflake Environment Setup" duration="5">
        <p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Establish the Snowpark Python session</li>
<li>Create the database, schema, and warehouses needed for the remainder of the lab</li>
<li>Load raw csv data into Snowflake</li>
<li>Accept Anaconda terms &amp; conditions to enable 3rd-Party packages</li>
</ul>
<p>First of all, locate the following information:</p>
<ul>
<li>Username</li>
<li>Password</li>
<li><a href="https://docs.snowflake.com/en/user-guide/organizations-gs.html#viewing-the-name-of-your-organization-and-its-accounts" target="_blank">Organization- and Accountname</a></li>
</ul>
<p>You&#39;ll need these values to connect to your Snowflake Account via Snowpark.</p>
<p>After that, open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/0_setup_environment.ipynb" target="_blank"><code>0_setup_environment</code></a> Jupyter notebook and run each of the cells to setup your Snowflake Account and load the required datasets into Snowflake.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Data Exploration and Transformation" duration="20">
        <h2 is-upgraded>Demo</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Understand the difference between Snowpark DataFrames and Pandas DataFrames</li>
<li>Performing simple data transformations</li>
<li>Performing simple data analysis</li>
<li>Persist your analysis results</li>
</ul>
<p>Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/1_1_DEMO_basic_data_exploration_transformation.ipynb" target="_blank"><code>1_1_DEMO_basic_data_exploration_transformation</code></a> Jupyter notebook and run each of the cells.</p>
<h2 is-upgraded>Excercise</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Test your understanding of working with Snowpark DataFrames</li>
<li>Answer basic questions about your data by using the Snowpark-API</li>
<li>Create a new feature variable</li>
</ul>
<p>Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/1_2_EXERCISE_basic_data_exploration_transformation.ipynb" target="_blank"><code>1_2_EXERCISE_basic_data_exploration_transformation</code></a> Jupyter notebook and develop/adjust the code to solve the tasks.</p>
<h2 is-upgraded>Solution</h2>
<p>You can verify your excercise results by having a look at the solution provided in the  <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/1_2_SOLUTION_basic_data_exploration_transformation.ipynb" target="_blank"><code>1_2_SOLUTION_basic_data_exploration_transformation</code></a> Jupyter notebook.</p>
<h2 is-upgraded>Demo</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Transform the data into a final dataset ready to be used as input for machine learning models</li>
<li>Variable analysis</li>
<li>Missing value imputation</li>
<li>Create the target variable</li>
<li>Variable encoding</li>
<li>Synthetic Minority Oversampling via Snowflake Stored Procedure</li>
</ul>
<p>Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/1_3_DEMO_full_data_exploration_transformation.ipynb" target="_blank"><code>1_3_DEMO_full_data_exploration_transformation</code></a> Jupyter notebook and run each of the cells.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Model Building &amp; Deployment" duration="15">
        <h2 is-upgraded>Demo</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Develop a Stored Procedure to train a simple logistic regression model with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank">scikit-learn</a></li>
<li>Deploy the trained model as a User Defined Function</li>
<li>Score the model on unseen data and evaluate model metrics</li>
</ul>
<p>Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/2_1_DEMO_model_building_scoring.ipynb" target="_blank"><code>2_1_DEMO_model_building_scoring</code></a> Jupyter notebook and run each of the cells.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Vectorizing &amp; Caching for UDFs" duration="10">
        <h2 is-upgraded>Demo</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Improve the performance of your existing User Defined Function with vectorization and caching</li>
<li>Understand how caching and vectorization work</li>
</ul>
<p>Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/3_1_DEMO_vectorized_cached_scoring.ipynb" target="_blank"><code>3_1_DEMO_vectorized_cached_scoring</code></a> Jupyter notebook and run each of the cells.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Building Additional Models" duration="20">
        <h2 is-upgraded>Excercise</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Apply your knowledge of Stored Procedures and User Defined Functions to develop additional models</li>
<li>You can choose between <a href="https://github.com/dmlc/xgboost" target="_blank">XGBoost</a> or <a href="https://github.com/microsoft/LightGBM" target="_blank">LightGBM</a> as your additional model</li>
</ul>
<p><strong>For XGBoost:<br></strong> Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/4_1_EXERCISE_additional_models_xgboost.ipynb" target="_blank"><code>4_1_EXERCISE_additional_models_xgboost</code></a> Jupyter notebook and develop/adjust the code to solve the tasks.</p>
<p><strong>For LightGBM:<br></strong> Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/4_2_EXERCISE_additional_models_lightgbm.ipynb" target="_blank"><code>4_2_EXERCISE_additional_models_lightgbm</code></a> Jupyter notebook and develop/adjust the code to solve the tasks.</p>
<h2 is-upgraded>Solution</h2>
<p><strong>For XGBoost:<br></strong> You can verify your excercise results by having a look at the solution provided in the  <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/4_1_SOLUTION_additional_models_xgboost.ipynb" target="_blank"><code>4_1_SOLUTION_additional_models_xgboost</code></a> Jupyter notebook.</p>
<p><strong>For LightGBM:<br></strong> You can verify your excercise results by having a look at the solution provided in the  <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/4_2_SOLUTION_additional_models_lightgbm.ipynb" target="_blank"><code>4_2_SOLUTION_additional_models_lightgbm</code></a> Jupyter notebook.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Hyperparameter Tuning with Optuna" duration="10">
        <h2 is-upgraded>Demo</h2>
<p><strong>What You&#39;ll Do</strong>:</p>
<ul>
<li>Utilize <a href="https://github.com/optuna/optuna" target="_blank">Optuna</a> to perform hyper parameter tuning inside a Stored Procedure</li>
<li>Deploy the optimized model with a User Defined Function</li>
<li>Evaluate the resulting model</li>
</ul>
<p>Open up the <a href="https://github.com/Snowflake-Labs/sfguide-getting-started-machine-learning/blob/main/hol/5_1_DEMO_hyperparameter_tuning_optuna.ipynb" target="_blank"><code>5_1_DEMO_hyperparameter_tuning_optuna</code></a> Jupyter notebook and run each of the cells.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Conclusion" duration="2">
        <p>Through this Quickstart we were able to experience how Snowpark for Python enables you to use familiar syntax and constructs to process data where it lives with Snowflake&#39;s elastic, scalable and secure engine, accelerating the path to production for data pipelines and ML workflows. Here&#39;s what you were able to complete:</p>
<ul>
<li>Loading and transforming data via Snowpark</li>
<li>Defining Stored Procedures for non-SQL-based Data Transformations</li>
<li>Defining Stored Procedures for training different machine learning models</li>
<li>Defining User Defined Functions for distributed scoring of machine learning models</li>
<li>Using hyper paratemer tuning in Stored Procedures</li>
</ul>
<p>For more information on Snowpark Python, and Machine Learning in Snowflake, check out the following resources:</p>
<ul>
<li><a href="https://docs.snowflake.com/en/developer-guide/snowpark/python/index.html" target="_blank">Snowpark Python Developer Guide</a></li>
<li><a href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/index.html" target="_blank">Snowpark Python API Docs</a></li>
</ul>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/native-shim.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/custom-elements.min.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/prettify.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>
  <script type="text/javascript">
    window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
    heap.load("2025084205");
  </script>
</body>
</html>
