
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>A Image Recognition App in Snowflake using Snowpark Python, PyTorch, Streamlit and OpenAI</title>

  
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5Q8R2G');</script>
  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-08H27EW14N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-08H27EW14N');
</script>

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://quickstarts.snowflake.com/elements/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5Q8R2G"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  
  <google-codelab-analytics gaid="UA-41491190-9"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="image_recognition_snowpark_pytorch_streamlit_openai"
                  title="A Image Recognition App in Snowflake using Snowpark Python, PyTorch, Streamlit and OpenAI"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Overview" duration="2">
        <p>In this guide, we will review how to build image recognition applications in Snowflake using Snowpark for Python, PyTorch, Streamlit and OpenAI&#39;s DALL-E 2â€Šâ€“â€Š&#34;<em>a new AI system that can create realistic images and art from a description in natural language</em>&#34;.</p>
<p>First things first though for those that are new to some of these technologies.</p>
<h2 is-upgraded>What is Snowpark?</h2>
<p>It allows developers to query data and write data applications in languages other than SQL using a set of APIs and DataFrame-style programming constructs in Python, Java, and Scala. These applications run on and take advantage of the same distributed computation on Snowflake&#39;s elastic engine as your SQL workloads. Learn more about <a href="https://www.snowflake.com/snowpark/" target="_blank">Snowpark</a>.</p>
<h2 is-upgraded>What is Streamlit?</h2>
<p>Streamlit is a pure-Python <a href="https://github.com/streamlit/streamlit" target="_blank">open source</a> application framework that enables developers to quickly and easily write, share, and deploy data applications. Learn more about <a href="https://streamlit.io/" target="_blank">Streamlit</a>.</p>
<h2 is-upgraded>What is PyTorch?</h2>
<p>It is one of the most popular <a href="https://github.com/pytorch/pytorch" target="_blank">open source</a> machine learning frameworks that also happens to be pre-installed and available for developers to use in Snowpark via <a href="https://snowpark-python-packages.streamlit.app/" target="_blank">Snowflake Anaconda</a> channel. This means that you can load pre-trained PyTorch models in Snowpark for Python without having to manually install the library and manage all its dependencies.</p>
<h2 is-upgraded>OpenAI and DALL-E 2</h2>
<p>Learn more about <a href="https://openai.com/" target="_blank">OpenAI</a> and <a href="https://openai.com/dall-e-2/" target="_blank">DALL-E 2</a>.</p>
<h2 is-upgraded>What You&#39;ll Build</h2>
<p>Two web-based image recognition applications in Streamlit. These applications call Snowpark for Python User-Defined Function (UDF) that uses PyTorch for image recognition.</p>
<ol type="1">
<li>The first application let&#39;s the user <strong>upload an image</strong>.</li>
<li>The second application uses OpenAI&#39;s DALL-E 2 to <strong>generate an image</strong> based on user input in text/natural language format.</li>
</ol>
<h3 is-upgraded>IMP: In both applications, the Snowpark for Python UDF that uses PyTorch for image recognition running in Snowflake is exactly the same. Which is awesome!</h3>
<h2 class="checklist" is-upgraded>What You&#39;ll Learn</h2>
<ul class="checklist">
<li>How to work with Snowpark for Python APIs</li>
<li>How to use pre-trained models for image recognition using PyTorch in Snowpark</li>
<li>How to create Snowpark Python UDF and deploy it in Snowflake</li>
<li>How to call Snowpark for Python UDF in Streamlit</li>
<li>How to run Streamlit applications</li>
</ul>
<h2 is-upgraded>Prerequisites</h2>
<ul>
<li>A <a href="https://signup.snowflake.com/" target="_blank">Snowflake account</a><ul>
<li>Login to your Snowflake account with the admin credentials that were created with the account in one browser tab (a role with ORGADMIN privileges). Keep this tab open during the session. <ul>
<li>Click on the <strong>Billing</strong> on the left side panel</li>
<li>Click on <strong>Terms and Billing</strong></li>
<li>Read and accept terms to continue</li>
</ul>
</li>
<li>Create a <a href="https://docs.snowflake.com/en/sql-reference/sql/create-warehouse.html" target="_blank">Warehouse</a>, a <a href="https://docs.snowflake.com/en/sql-reference/sql/create-database.html" target="_blank">Database</a> and a <a href="https://docs.snowflake.com/en/sql-reference/sql/create-schema.html" target="_blank">Schema</a></li>
</ul>
</li>
<li>(<strong><em>Optionally</em></strong>) <a href="https://beta.openai.com/overview" target="_blank">OpenAI account</a> for creating the second application. Once the account is created, you will need to generate an <a href="https://beta.openai.com/account/api-keys" target="_blank">OpenAI API key</a> to use in the application. <em>Note: At the time of writing this guide, creating a new OpenAI account granted you $18.00 credit which is plenty for this application.</em></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Streamlit Applications" duration="5">
        <p>Now let&#39;s review the two image recognition applications you&#39;ll build in Streamlit.</p>
<h2 is-upgraded>Application 1â€Š-â€ŠUpload an image</h2>
<p>This application uses Streamlit&#39;s <a href="https://docs.streamlit.io/library/api-reference/widgets/st.file_uploader" target="_blank"><em>st.file_uploader()</em></a> to allow the user to upload an image file. Once the file is uploaded successfully, the following code snippet converts image data from base64 to hex and stores it in a Snowflake table using a very handy Snowpark API <a href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/api/snowflake.snowpark.Session.write_pandas.html" target="_blank"><em>session.write_pandas()</em></a>.</p>
<p>Here&#39;s the code snippet:</p>
<pre><code language="language-python" class="language-python">uploaded_file = st.file_uploader(&#34;Choose an image file&#34;, accept_multiple_files=False, label_visibility=&#39;hidden&#39;)
if uploaded_file is not None:
  # Convert image base64 string into hex 
  bytes_data_in_hex = uploaded_file.getvalue().hex()

  # Generate new image file name
  file_name = &#39;img_&#39; + str(uuid.uuid4())

  # Write image data in Snowflake table
  df = pd.DataFrame({&#34;FILE_NAME&#34;: [file_name], &#34;IMAGE_BYTES&#34;: [bytes_data_in_hex]})
  session.write_pandas(df, &#34;IMAGES&#34;)
</code></pre>
<h2 is-upgraded>Application 2 - OpenAI generated image</h2>
<p>This application uses OpenAI&#39;s API <a href="https://beta.openai.com/docs/guides/images/generations" target="_blank"><em>openai.Image.create()</em></a> to generate images based on the description provided by the user in the form of text/natural languageâ€Š-â€Šin real-time! Then, similar to the first application, the generated image data is converted from base64 into hex and that image data is stored in a Snowflake table using a very handy Snowpark API <em>session.write_pandas()</em>.</p>
<p>Here&#39;s the code snippet:</p>
<pre><code language="language-python" class="language-python"># Retrieve OpenAI key from environment variable
openai.api_key = os.getenv(&#34;OPENAI_API_KEY&#34;)

# Add text box for entering text
text_input = st.text_input(&#34;Enter description of your favorite animal ðŸ‘‡&#34;)
if text_input:
   response = openai.Image.create(
      prompt=text_input,
      n=1,
      size=&#34;512x512&#34;,
      response_format=&#34;b64_json&#34;
   )

  # Convert image base64 string into hex
  image_bytes = response[&#39;data&#39;][0][&#39;b64_json&#39;]
  bytes_data_in_hex = base64.b64decode(image_bytes).hex()

  # Generate new image file name
  file_name = &#39;img_&#39; + str(uuid.uuid4())

  # Decode base64 image data and generate image file that can be used to display on screen 
  decoded_data = base64.b64decode((image_bytes))
  with open(file_name, &#39;wb&#39;) as f:
    f.write(decoded_data)

  # Write image data in Snowflake table
  df = pd.DataFrame({&#34;FILE_NAME&#34;: [file_name], &#34;IMAGE_BYTES&#34;: [bytes_data_in_hex]})
  session.write_pandas(df, &#34;IMAGES&#34;)
</code></pre>
<p>Notes:</p>
<ul>
<li>It&#39;s assumed that you&#39;ve stored your OpenAI API key in an environment variable named <strong><em>OPENAI_API_KEY</em></strong>. If not, change the code accordingly before running the app.</li>
<li>The reason behind writing the image file locally is so that the generated image (by OpenAI) can be displayed in the browser. (Note that the image file is deleted after it&#39;s displayed.)</li>
</ul>
<h2 is-upgraded>In Both Applications</h2>
<ul>
<li>Streamlit&#39;s <em>st.set_page_config(), st.header(), st.caption(), st.columns() and st.container()</em> are used to organize and display various components of the application.</li>
<li>For simplicity, the hex image data is stored in String format in a Snowflake table.</li>
<li>The Snowpark for Python UDF <em>image_recognition_using_bytes()</em> that uses PyTorch for image recognition running in Snowflake is the same and is invoked as shown below.</li>
</ul>
<pre><code language="language-python" class="language-python"># Call Snowpark User-Defined Function to predict image label
predicted_label = session.sql(f&#34;SELECT image_recognition_using_bytes(image_bytes) as PREDICTED_LABEL from IMAGES where FILE_NAME = &#39;{file_name}&#39;&#34;).to_pandas().iloc[0,0]
</code></pre>
<ul>
<li>In the above code snippet, the Snowpark for Python UDF <em>image_recognition_using_bytes()</em> is passed the contents of the column <em>image_bytes</em> where the column <em>FILE_NAME</em> matches the name of the image file generated using uuid.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Snowpark for Python and PyTorch" duration="10">
        <p>For this particular application, we will be using <a href="https://github.com/d-li14/mobilenetv3.pytorch" target="_blank">PyTorch implementation of MobileNet V3</a>.</p>
<p><em>Note: A huge thank you to the </em><a href="https://github.com/d-li14/mobilenetv3.pytorch#citation" target="_blank"><em>authors</em></a><em> for the research and making the pre-trained models available under </em><a href="https://github.com/d-li14/mobilenetv3.pytorch/blob/master/LICENSE" target="_blank"><em>MIT License</em></a><em>.</em></p>
<p>Ok, so once we have access to the pre-trained model files, we need to upload them onto Snowflake (internal) stage using Snowpark API <a href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/api/snowflake.snowpark.FileOperation.put.html#snowflake.snowpark.FileOperation.put" target="_blank"><em>session.file.put()</em></a> so that they can be added as dependencies on the Snowpark for Python UDF for inference.</p>
<p>Here&#39;s the code snippet:</p>
<pre><code language="language-python" class="language-python">session.file.put(&#39;imagenet1000_clsidx_to_labels.txt&#39;,&#39;@dash_files&#39;,overwrite=True,auto_compress=False)
session.file.put(&#39;mobilenetv3.py&#39;,&#39;@dash_files&#39;,overwrite=True,auto_compress=False)
session.file.put(&#39;mobilenetv3-large-1cd25616.pth&#39;,&#39;@dash_files&#39;,overwrite=True,auto_compress=False)
</code></pre>
<p>And here&#39;s the Snowpark for Python UDF code that uses the pre-trained model for image recognition in <strong><em>both applications</em></strong>.</p>
<pre><code language="language-python" class="language-python"># Add model files as dependencies on the UDF
session.add_import(&#39;@dash_files/imagenet1000_clsidx_to_labels.txt&#39;)
session.add_import(&#39;@dash_files/mobilenetv3.py&#39;)
session.add_import(&#39;@dash_files/mobilenetv3-large-1cd25616.pth&#39;)

# Add Python packages from Snowflke Anaconda channel
session.add_packages(&#39;snowflake-snowpark-python&#39;,&#39;torchvision&#39;,&#39;joblib&#39;,&#39;cachetools&#39;)

@cachetools.cached(cache={})
def load_class_mapping(filename):
  with open(filename, &#34;r&#34;) as f:
   return f.read()

@cachetools.cached(cache={})
def load_model():
  import sys
  import torch
  from torchvision import models, transforms
  import ast
  from mobilenetv3 import mobilenetv3_large

  IMPORT_DIRECTORY_NAME = &#34;snowflake_import_directory&#34;
  import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]

  model_file = import_dir + &#39;mobilenetv3-large-1cd25616.pth&#39;
  imgnet_class_mapping_file = import_dir + &#39;imagenet1000_clsidx_to_labels.txt&#39;

  IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))

  transform = transforms.Compose([
      transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),
      transforms.CenterCrop(224),
      transforms.ToTensor(),
      transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)
  ])

  # Load the Imagenet {class: label} mapping
  cls_idx = load_class_mapping(imgnet_class_mapping_file)
  cls_idx = ast.literal_eval(cls_idx)

  # Load pretrained image recognition model
  model = mobilenetv3_large()
  model.load_state_dict(torch.load(model_file))

  # Configure pretrained model for inference
  model.eval().requires_grad_(False)
  return model, transform, cls_idx

def load_image(image_bytes_in_str):
  import os
  image_file = &#39;/tmp/&#39; + str(os.getpid())
  image_bytes_in_hex = bytes.fromhex(image_bytes_in_str)

  with open(image_file, &#39;wb&#39;) as f:
    f.write(image_bytes_in_hex)
  return open(image_file, &#39;rb&#39;)

@udf(name=&#39;image_recognition_using_bytes&#39;,session=session,replace=True,is_permanent=True,stage_location=&#39;@dash_files&#39;)
def image_recognition_using_bytes(image_bytes_in_str: str) -&gt; str:
  import sys
  import torch
  from PIL import Image
  import os

  model, transform, cls_idx = load_model()
  img = Image.open(load_image(image_bytes_in_str))
  img = transform(img).unsqueeze(0)

  # Get model output and human text prediction
  logits = model(img)

  outp = torch.nn.functional.softmax(logits, dim=1)
  _, idx = torch.topk(outp, 1)
  idx.squeeze_()
  predicted_label = cls_idx[idx.item()]
  return f&#34;{predicted_label}&#34;
</code></pre>
<p>Notes:</p>
<ul>
<li>There are two ways to deploy Python functions as UDFs in Snowpark so that they&#39;re executed in Snowflake. One is to use <a href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/api/snowflake.snowpark.functions.udf.html#snowflake.snowpark.functions.udf" target="_blank"><em>@udf decorator</em></a> as shown above in image_recognition_using_bytes() and the other is to use <a href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/api/snowflake.snowpark.udf.UDFRegistration.register.html#snowflake.snowpark.udf.UDFRegistration.register" target="_blank">register()</a>.</li>
<li>Because functions <em>load_class_mapping(), load_image()</em>, and <em>load_model()</em> are global objects, they&#39;re also serialized and available in <em>image_recognition_using_bytes()</em> UDF.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Setup Environment" duration="5">
        <p>In order to build and run the applications, setup your environment as described below.</p>
<ul>
<li>Clone <a href="https://github.com/Snowflake-Labs/sfguide-snowpark-pytorch-streamlit-openai-image-rec" target="_blank">GitHub repository</a> and browse to the app folder <em>sfguide-snowpark-pytorch-streamlit-openai-image-rec</em></li>
<li>Download the miniconda installer from <a href="https://conda.io/miniconda.html" target="_blank">https://conda.io/miniconda.html</a>. <em>(OR, you may use any other Python environment with Python 3.8)</em>.</li>
<li>From the app folder, create conda environment. Then activate conda environment and install Snowpark for Python and other libraries including Streamlit. <em>Note: You can skip installing openai if you&#39;re not going to run the second application.</em></li>
</ul>
<pre><code language="language-python" class="language-python">conda create --name snowpark-img-rec -c https://repo.anaconda.com/pkgs/snowflake python=3.8
conda activate snowpark-img-rec
conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python pandas notebook cachetools
pip install streamlit
pip install uuid
pip install openai
</code></pre>
<p><em>Note: The versions at the time of writing this â€“ snowflake-snowpark-python 1.0.0, streamlit 1.16.0, openai 0.26.0.</em></p>
<ul>
<li>Update <a href="https://github.com/Snowflake-Labs/sfguide-snowpark-pytorch-streamlit-openai-image-rec/blob/main/connection.json" target="_blank">connection.json</a> with your Snowflake account details and credentials. <em>Note: For the account parameter, specify your </em><a href="https://docs.snowflake.com/en/user-guide/admin-account-identifier.html" target="_blank"><em>account identifier</em></a><em> and do not include the snowflakecomputing.com domain name. Snowflake automatically appends this when creating the connection.</em></li>
<li>In your Snowflake account, create a Snowflake table and internal stage by running the following commands in Snowsight. The table will store the image data and the stage is for storing serialized Snowpark Python UDF code. <em>Note: It&#39;s assumed that you&#39;ve already created a warehouse, a database and a schema in your Snowflake account.</em></li>
</ul>
<pre><code language="language-sql" class="language-sql">create or replace table images (file_name string, image_bytes string);
create or replace stage dash_files;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Build and Run Applications" duration="5">
        <p>Once you have satisfied the prerequisites and set up your environment as described, running the two applications is pretty straightforward.</p>
<ul>
<li>In your favorite IDE such as Jupyter Notebook or VS Code, set the Python kernel to <strong>snowpark-img-rec</strong> (the name of the conda environment created in the previous step) and then run through the cells in <a href="https://github.com/Snowflake-Labs/sfguide-snowpark-pytorch-streamlit-openai-image-rec/blob/main/Snowpark_PyTorch_Image_Rec.ipynb" target="_blank">Snowpark_PyTorch_Image_Rec.ipynb</a>.</li>
<li>Once every cell runs without any errors, you can check the contents of the Snowflake stage to make sure the model files and the UDF exists by running the following command in Snowsight. <em>Note: Replace the name of the stage with the one you created.</em></li>
</ul>
<pre><code language="language-sql" class="language-sql">list @dash_files;
</code></pre>
<h2 is-upgraded>Application 1 - Upload image</h2>
<ul>
<li>In a terminal window, execute the following command from the app folder <em>sfguide-snowpark-pytorch-streamlit-openai-image-rec</em> to run Streamlit application <a href="https://github.com/Snowflake-Labs/sfguide-snowpark-pytorch-streamlit-openai-image-rec/blob/main/Snowpark_PyTorch_Streamlit_Upload_Image_Rec.py" target="_blank">Snowpark_PyTorch_Streamlit_Upload_Image_Rec.py</a></li>
</ul>
<pre><code language="language-shell" class="language-shell">streamlit run Snowpark_PyTorch_Streamlit_Upload_Image_Rec.py
</code></pre>
<ul>
<li>If all goes well, you should see a browser window open with the app loaded. Then, after uploading an image of your favorite animal by clicking on <strong>Browse files</strong> button, you should see something similar to this...</li>
</ul>
<p class="image-container"><img alt="Snowpark_PyTorch_Streamlit_Upload_Image_Rec" src="img/81e9e7daa2e39e55.png"></p>
<h2 is-upgraded>Application 2 - Generate images using OpenAI</h2>
<ul>
<li>In a terminal window, execute the following command from the app folder <em>sfguide-snowpark-pytorch-streamlit-openai-image-rec</em> to run Streamlit application <a href="https://github.com/Snowflake-Labs/sfguide-snowpark-pytorch-streamlit-openai-image-rec/blob/main/Snowpark_PyTorch_Streamlit_OpenAI_Image_Rec.py" target="_blank">Snowpark_PyTorch_Streamlit_OpenAI_Image_Rec.py</a></li>
</ul>
<pre><code language="language-shell" class="language-shell">streamlit run Snowpark_PyTorch_Streamlit_OpenAI_Image_Rec.py
</code></pre>
<ul>
<li>If all goes well, you should see a browser window open with the app loaded. Then, enter text like so &#34;<strong>I&#39;d like to see a polar bear cub playing in snow!</strong>&#34; and you should see something similar to this...</li>
</ul>
<p class="image-container"><img alt="Snowpark_PyTorch_Streamlit_OpenAI_Image_Rec" src="img/99a0aacd84ade333.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Conclusion And Resources" duration="1">
        <p>Congratulations! You&#39;ve successfully created image recognition applications in Snowflake using Snowpark for Python, PyTorch, Streamlit and OpenAI.</p>
<h2 is-upgraded>What You Learned</h2>
<ul>
<li>How to work with Snowpark for Python APIs</li>
<li>How to use pre-trained models for image recognition using PyTorch in Snowpark</li>
<li>How to create Snowpark Python UDF and deploy it in Snowflake</li>
<li>How to call Snowpark for Python UDF in Streamlit</li>
<li>How to run Streamlit applications</li>
</ul>
<h2 is-upgraded>Related Resources</h2>
<ul>
<li><a href="https://github.com/Snowflake-Labs/sfguide-snowpark-pytorch-streamlit-openai-image-rec" target="_blank">Source Code on GitHub</a></li>
<li><a href="https://quickstarts.snowflake.com/guide/getting_started_snowpark_machine_learning/index.html" target="_blank">Machine Learning with Snowpark for Python</a></li>
<li><a href="https://github.com/Snowflake-Labs/snowpark-python-demos/blob/main/README.md" target="_blank">Snowpark for Python Demos</a></li>
<li><a href="https://docs.snowflake.com/en/developer-guide/snowpark/python/index.html" target="_blank">Snowpark for Python Developer Guide</a></li>
<li><a href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/index.html" target="_blank">Snowpark for Python API Reference</a></li>
<li><a href="https://docs.streamlit.io/" target="_blank">Streamlit Docs</a></li>
</ul>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/native-shim.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/custom-elements.min.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/prettify.js"></script>
  <script src="https://quickstarts.snowflake.com/elements/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>
  <script type="text/javascript">
    window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
    heap.load("2025084205");
  </script>
</body>
</html>
